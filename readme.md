YouTube Data Project
Isaac Brooks

Included Files:
    ScrapeYoutube2.py
    YoutubePredict.py
    YoutubeVisualize.py
    LinusTechTips_2019562315_scrape.csv
    key.json                            [sensitive, please be careful]
    ScrapeYoutube-2d857f0f6524.json     [sensitive, please be careful]

Table of Contents:

0. Setup
1. ScrapeYoutube Description
2. YoutubeVisualize Description
3. YoutubePredict Description
4. Unresolved Issues





0. -------------------- Setup --------------------
Requird packages:
    pandas
    scipy
    sklearn
    selenium w/ geckodriver
    google-api-python-client
    google-auth-oauthlib
    google-auth-httplib2

Additional Setup:
For the Youtube Data API to work correctly an environment variable must be set like the following:

    Windows via Powershell:
    $env:GOOGLE_APPLICATION_CREDENTIALS= (path to ScrapeYoutube-2d857f0f6524.json)

    Linux:
    export GOOGLE_APPLICATION_CREDENTIALS= (path to ScrapeYoutube-2d857f0f6524.json)

--------------------------------------------------



1. ---------------- ScrapeYoutube ----------------
ScrapeYoutube2.py is a API driven scraper for any given Youtube channel.
It will load a channels entire* (see unresolved issue #1) video list and store the following from each video:
    Video Name,
    Video Tags,
    Number of Likes,
    Number of Dislikes,
    Like/Dislike Ratio,
    Date Published,
    Time Published,
    Number of Views,
    Category,
    Number of Comments,
    URL.

On startup, the user will be asked if they wish to restart from a previous run, more on that later.
If no is selected, the user will be prompted for a channel or user in one of the following formats:
    http://www.youtube.com/user/(user name here)/videos
    http://www.youtube.com/user/(user name here)/
    http://www.youtube.com/channel/(channel name here)/videos
    http://www.youtube.com/channel/(user name here)/

    If an invalid or blank URL is entered, ScrapeYoutube will default to LinusTechTips.

Once a valid URL is entered the user will be prompted whether they want to enable full channel searching.
Full channel searching enables the web scraper to load the entire list of videos.
If full channel searching is not enabled, the first 30 videos will be loaded.
If full channel searching is enabled, the user will be asked if they would like to set a limit on scrolling.

If no is selected, the list will be scrolled down (loading more videos each time) until the bottom is found.
If yes is selected, the user will be prompted for a number. On average, 30 more videos are loaded with each scroll.
Therefore, the number of videos to be loaded can be found by the equation (30 + (30 x n)) where n is the number of times to scroll down.

Once the video list is populated and acquired, selenium will exit and ScrapeYoutube will switch to the YouTube Data API.
Every video in the list will be scraped and printed to a CSV file in real time, as well as stored to a list of dictionaries.
On completion the list of dictionaries will be dumped to a file.

FILE NAMING:
Data files produced by ScrapeYoutube2.py are named according to the following formula:
ChannelName_(year)(month)(day)(hour)(minute)_scrape.(csv/json)

API DATA CAP:
If ScrapeYoutube2.py reaches max calls to the YouTube Data API before it is finished, it will save the following:
    Name of the CSV file,
    Current time stamp,
    ChannelID,
    Current list of videos,
    Position in list of videos.

If a user had entered yes at startup when prompted to restart from a previous scrape, it will search for resume.json.
If resume.json is found it will start back where it left off from the previous scrape.
If resume.json is not found, it will exit with an error.

The YouTube Data API cap is reset at 3:00AM PDT.

--------------------------------------------------



2. --------------- YoutubeVisualize --------------
YoutubeVisualize.py produces visuals using the data acquired by ScrapeYoutube2.py
The following visuals are produced:
    A graph of Likes and Dislikes on every video, X axis is time.
    A graph of Views, Likes, and Dislikes on every video, X axis is time.
    A scatter plot of the number of comments vs the sum of likes and dislikes.
    4x box and whisker plots for Views, Likes, Dislikes, and Comments.
    3 graphs showing top 20 tags based on the total views, likes, and dislikes respectively.

Each of these visuals will be saved as a PNG file.
On startup, the user will be prompted for a filename. YoutubeVisualize accepts CSV files generated by ScrapeYoutube2.
These files will be found in the form specified in section 1.

Due to the production of an additional dataframe for dealing with data relating to video tags, the first run on a
dataset will take several minutes. Once this dataframe is generated it will be output to a CSV file, allowing subsequent
runs to be almost instant.

FILE NAMING:
Data files produced by YoutubeVisualize.py are named according to the following formula:
ChannelName_(year)(month)(day)(hour)(minute)_tagData.csv

--------------------------------------------------



3. ---------------- YoutubePredict ---------------
YoutubePredict.py uses the data acquired from ScrapeYoutube2.py to make predictions.
It will produce the following models:
    Model 1. Bag of words model using video tags to predict number of views.
    Model 2. Bag of words model using video title to predict number of views.
    Model 3. Polynomial model using number of views to predict number of likes.
    Model 4. Linear regression model using sum of likes and dislikes to predict number of comments.

Each model is verified using the train/validation/test set approach.
On startup the user will be prompted for a filename. YoutubePredict accepts CSV files generated by ScrapeYoutube2.
These files will be found in the form specified in section 1.

Model 1.
    Model 1 is a bag-of-words model using CountVectorizer combined with TruncatedSVD and HuberRegressor to
    predict the number of views for a given vieo based on the video's tags.

Model 2.
    Model 2 is a bag-of-words model using CountVectorizer combined with TruncatedSVD and LinearRegression to 
    predict the number of views for a given video based on the video's title.

Model 3.
    Model 3 is a polynomial regression model using PolynomialFeatures of degree 3 and LinearRegression to predict
    the number of likes for a given video based on the number of views.

Model 4.
    Model 4 is a linear regression model using LinearRegression to predict the number of comments for a given
    video bassed on the sum of likes and dislikes.

--------------------------------------------------



4. -------------- Unresolved Issues --------------

#1. ScrapeYoutube2.py does not load the entire video list of a channel. It will always stop at 3000.
    This is likely due to the way the videos are dynamically loaded on a given user's video page.

#2. ScrapeYoutube2.py is unable to encode certain 'emoji' characters. This result in an ERROR row in
    the result CSV file.

